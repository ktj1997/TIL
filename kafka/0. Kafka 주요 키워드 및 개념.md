# 0. Kafka 개념 및 이해

## Kafka란?
- Data in Mintion Platform
  - 움직이는 데이터를 처리하는 플랫폼이다. 
- EventStreaming Platform
  - Event가 발생했을 때 Evnet를 필요로 하는 곳으로 데이터를 전달해준다.
- Source Application과 TargetApplication의 강결합을 막을 수 있다.

### Event란?
- 비즈니스에서 일어나는 모든 일(데이터) 를 의미한다.
- 비즈니스 영역에서 광범위 하게 발생한다.
- Big Data로 발생한다.
  - 많은 Event가 발생하여 Big Data만큼 되기 때문에, EventStream이라고 한다.

### Kafka의 3가지 특징
#### 1. Event Stream을 안전하게 전송
#### 2. EventStream을 Disk에 저장한다.
#### 3. EventStream을 분석 및 처리

### Kafka 주요 사용 사례

#### 1. Messaging System
#### 2. IOT 디바이스로부터 데이터 수집
#### 3. Application에서 발생하는 Log 수집
#### 4. RealTimeEventStreaming Prodcessing (이상감지 등)
#### 5. DB동기화 (MSA 기반의 분리된 DB 동기화)

***

## Message
- 아래와 같은 동의어들이 있다.
  - Record
  - Event
  - Message
  - Data
- Header(MetaData: Topic, Partition, Timestamp ... ), Key, Value로 이루어 진다.
- 직렬화를 통해 ByteArray로 구성된다.

***

## Topic
- Message가 저장되는 저장 장소
  - DB의 테이블이나, FileSystem의 폴더와 유사하다.
- 논리적인 표현 방식이다.
- Producer가 공급하고, Consumer가 소비한다.
  - Producer와 Consumer는 서로를 알지 못한다.
  - Producer와  Consumer는 각자의 속도로 Read와 Write를 수행한다.
- 내부적으로 하나 이상의 Partition으로 구성된다.
  - Producer가 보낸 Message는 Topic 내부의 Partition중 하나에 저장된다.

### Topic 내의 모든 Message 순서보장
- 복수개의 Partition이 존재하면 순서가 보장되지 않는다.
- 모든 Message순서를 보장하려면, **Partition 1개**만 사용해야 한다.

### Key를 이용한 순서보장
- 동일한 Key는 동일한 Partition에 전달이 된다.
- 순서보장이 필요할 경우, 동일한 Key의 Message를 통해 순서를 보장 할 수 있다.
- **파티션의 개수가 바뀌게되면 Global Relocation이 발생하기 떄문에 SideEffect가 발생할 수 있다.**
***

## Partition
- Queue(FIFO) 구조이다.
  - 오래된 순서대로 Consumer가 Message를 가져간다.
  - Consumer가 Consume하여도, 데이터는 삭제되지 않는다.
    - 옵션에 따라 삭제시점을 정할 수 있다. 
    - 다른 ConsumerGroup의 Consumer가 재사용 할 수 있다.
- Topic의 구성요소 이다.
- CommitLog이다.
  - Event들이 추가된다.
  - 추가만 가능하고 변경이 불가능하다.
  - offset이라는 것으로 접근 가능하다.
    - offset은 계속해서 증가한다.
  - Consumer Group끼리는 다른 Offset을 갖는다.
  - Producer와 Consumer의 Offset 차이를 Comsumer Lag라고 부른다.
- 병렬처리를 위해서 다수의 Partition을 사용한다.
- **Segement**라는 실제 Message가 저장되는 물리 File로 구성된다.
  - 지정된 크기가 커지거나(default 1GB), 오래되면(default 168 시간) 새로운 파일이 생성되고 추가된다.
- partition끼리는 서로 독립적이다.
  - offset 조차도 독립적이다.
- partition에 저장된 파일들은 Immutable하다.
- 고가용성을 위해서 복제(Replica) 한다.
  - 여러 Broker에 분산된다.
- ConsumerGroup내의 하나의 Consumer에 의해서만 사용된다.

### Key Cardinality
- Message의 Key값의 Hash를 통해서 Partition이 결정된다.
- 균등하게 분포되어있어야지 효율성이 올라간다.
***

## Broker
- Kafka Server라고 불린다. 
- Kafka Cluster를 구성하는 요소이다.
  - 최소 3대이상의 Broker를 사용하는 것을 권장한다.
- Partition에대한 Read, Write를 수행하는 소프트웨어 이다.
- Topic의 Partition 일부를 가지고 있다.
  - 일부분을 갖고있을 뿐, 전체 데이터를 갖고있지 않다.
- 하나의 Broker에만 연결해도 전체 Cluster에 접근 할 수 있다.
  - 하지만 해당 Broker가 장애가 발생하면, 접근 할 곳이 사라지므로 보통 모두 연결한다.

### Controller
- Kafka Cluster 내부의 Broker중 하나가 Controller가 된다.
- ZooKeeper로 부터 Broker Liveness를 모니터링 한다.
- Leader와 Replica 정보를 ZooKeeper로 부터 수신하고, 해당 정보를 Cluster내의 다른 Broker에게 전달한다.
- **Leader장애시 Controller가 Leader Election을 수행한다.**
- **Controller장애시 ActiveBroker중 하나가 Controller가 된다.**
***

## ZooKeeper
- Kafka Broker를 관리하는 소프트웨어 이다.
  - 분산 Configuration 정보 유지
  - 분산 동기화 서비스 제공
  - 네이밍 레지스트리 제공
- 분산작업을 제어하기위해서 Tree형태로 구성되어 있다.
- ZooKeeper 없이는 Kafka는 작동하지 않는다.
  - ZooKeeper를 제외한 버전 출시예정(2022)
- Cluster로 구성된다.
  - ZooKeeper Emsemble 이라고 부른다.  
    - Leader와 Follower로 나뉜다.
    - 홀수로 이루어진다.
    - Quorum(정족수) 알고리즘을 사용한다.

***

## Producer
- Kafka Topic으로 Message를 보내는 어플리케이션
- Serializer로 Message(==Record)를 직렬화 한다.
- Topic에 해당하는 Message를 보낸다.
  - 성공 여부를 확인 할 수 있으며, 재시도 또한 가능하다.

### 과정
1. Partitioner를 통해서 어느 Partition으로 보낼지 결정한다.
   - key가 있으면 Hash, 없으면 RoundRobin
   - Partition을 추가 할 수 없는 이유는, Partition 추가 시에, Key값에 따른 Hash가 깨지므로, 
     이전의 Key와 파티션과의 매칭의 동일성을 보장 할 수 없기 때문이다.
2. Compress(Optional)을 통해서 Message를 압축한다.
3. RecordAccumulator에서 Message를 모아서 Batch로 전송한다.

***

## Consumer
- Partition에서 Message를 가져와서 사용하는 어플리케이션
  - 순서대로 Read(Poll)를 수행한다.
  - Message를 읽은 위치를 Commit하여 다시 읽는 것을 방지한다.
- 다른 ConsumerGroup에 속한 Consumer들은 서로 연관이 없다.
  - 하나의 Topic에 여러 ConsumerGroup이 동시에 Read할 수 있다.
- 하나의 Consumer가 0개이상의 Partition 사용이 가능하다.
- Commited된 Message만 Read 할 수 있다.

### ConsumerGroup
- 동일한 group.id로 구성된 Consumer들이다.
- ConsumerGroup에 속한 Consumer들은 Partition을 분배하여 Consume한다.
  - ConsumerGroup이 동일한 Consumer는 동시에 Partition에 접근 할 수 없다. 
  - ConsumerGroup에 4개의 Consumer, Topic에 4개의 파티션이 있다면?
    - Consumer : Partition = 1 : 1 

***

## Replication
- 고가용성을 위한 방법이다.
- 미리 원본을 복사한 복제본을 준비하여, 장애가 발생했을 때를 미리 대비한다.
- Partition의 복제를 의미한다.
  - replication1 : 원본 1개
  - replication2 : 원본 1개 + 복제본 1개
- Broker의 숫자보다 많이 설정 할 수 없다.

### Partition Replication
- 원본을 Leader Patition, 복제본을 Follower Parition이라고 한다.
- Replication Factor 옵션은 n(원본 + 복제본) 이다.
- Leader Partition을 통해서만 Read와 Write가 진행된다.
  - kafka 2.4 부터는 FollowerParition Read가 가능해졌다.
  - 그렇기 때문에 Leader Parition에 대한 분배가 필요하다.
    - auto.leader.rebalance.enable (default도 enable)
- Follower Partition은 장애가 발생했을 떄를 대비해서 만들어지는 것이다.
  - Follower가 Leader의 CommitLog에서 FetchRequest를 통해서 복제한다.

#### 장애 발생 시
- Follower Partition 중에서 하나가 Leader Partition이 된다.
- Producer와 Consumer들 또한 새롭게 선출된 Leader로 데이터를 포워딩한다.
- Kafka Cluster가 Leader를 선출한다.

## InSyncReplication (ISR)
- Leader 장애시에, 새로운 Leader를 선출하는데 사용한다.
- HighWaterMark라는 지점까지의 동일한 Replica(Leader + Follower)의 목록이다.
- LeaderPartition + HighWaterMark까지 따라온 FollowerParition의 목록
- **LeaderParition의 Broker가 관리한다.**
  - Follower가 너무 느리면, Leader가 ISR에서 해당 Follower를 제거한다.
  - ZooKeeper에 보내고, Zookeeper가 공통설정 동기화를 유지해준다.
- ISR 목록의 모든 Replica가 Message를 성공적으로 가져오면 Commited되고, offset이 증가한다.
- ACK 옵션을 통해서, 데이터가 복제되었는지 확인하는 절차를 가진다.

### HighWaterMark
- Follower Partiton은 LeaderPartition의 모든 것을 복제하고 있지 않다.
  - 즉가즉각 동기화 하는 것은 불가능하기 때문이다.
  - Follower Partition끼리도 동기화의 차이가 있다.
- 가장 LeaderPartition과 근접한 FollowerPartition의 **LOG-END-OFFSET**을 HighWaterMark라고 한다. 
-  HighWaterMark를 갖고있는 FollowerParition은 **InSyncFollower가 된다.**

### replica.lag.max.messages
- LeaderParition의 LOG-END-OFFSET과 FollowerParition의 LOG-END-OFFSET의 차이를 지정하는 것이다.
- 이 범위 내부에 있으면 ISR(InSyncReplica), 밖에 있으면 OSR(OutSyncReplica) 이다.

#### replica.lag.max.messages로 ISR 판단시 문제점
- kafka에 항상 일정한 속도 및 비율로 Message가 들어올 수 없다.
- kafka는 메세지 유입량이 늘어날 경우, Latency로 판단하고 OSR로 변경한다.
  - 메세지 유입량이 많이 늘어나는 것을 Retry와 같은 작업이라고 판단한다.

### replica.lag.max.time.ms
- **이 옵션으로 대부분 ISR을 판단한다.**
- Follower가 Leader에게 Interval로 FetchRequest를 보낸다.
- Latency없이 지정 시간내에 FecthRequest를 보낸다면, ISR로 판단한다.
